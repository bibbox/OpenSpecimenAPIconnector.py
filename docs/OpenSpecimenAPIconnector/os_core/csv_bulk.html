<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>OpenSpecimenAPIconnector.os_core.csv_bulk API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>OpenSpecimenAPIconnector.os_core.csv_bulk</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /bin/python3

import pandas
import json
import io
import requests

from datetime import datetime

from .req_util import OS_request_gen
from .jsons import Json_factory
from .. import config_manager

class csv_bulk:
    &#34;&#34;&#34;Handles the OpenSpecimen CSV Bulk Importer via API.

    Handles the API calls of the OpenSpecimen&#39;s Bulk Importer for all the different schemas. 
    This class can get the templates to a schema, upload the csv-files, run the job, get the job status
    and get the job report.

    Note
    ----
    The OpenSpecimen Documentation of the Bulk Import can be seen at 
    https://openspecimen.atlassian.net/wiki/spaces/CAT/pages/440434702/Bulk+Import+via+API .
    File uploading in OpenSpecimen are two calls, which here are two seperated calls, via the
    function bulk_import from the os_util class bulk_operations these calls get one call.
    &#34;&#34;&#34;

    def __init__(self):

        &#34;&#34;&#34;Constructor of the class csv_bulk

        Constructor of the class csv_bulk. It also connects this class to the OpenSpecimen specific requests class
        OS_request_gen, and the OpenSpecimen standard JSON-dict generator class JSON_factory
        &#34;&#34;&#34;
        self.base_url = config_manager.get_url() + &#39;/import-jobs&#39;
        self.auth = config_manager.get_auth()
        self.OS_request_gen = OS_request_gen(self.auth)
        self.Json_fact = Json_factory()

    def ausgabe(self):

        &#34;&#34;&#34;Testing of the URL and authentification.

        If there are any unexpected errors, one can easily test if the URL and login data is spelled correctly.
        The function prints the URL and login data to the output terminal, which was handed over to the class.
        &#34;&#34;&#34;

        print(self.base_url, self.OS_request_gen.auth)


    def get_template(self, schemaname):
    
        &#34;&#34;&#34;Get the Templates to the corresponding schema

        Get the Templates of a OpenSpecimen schema and load it into an empty pandas dataframe,
        where the OpenSpecimen specific keys are the header of the dataframe. To use this class, one has to know the 
        schemanames which are used in OpenSpecimen. They are written in camelCase.

        Note
        ----
        The schemanames can be seen at: https://docs.google.com/spreadsheets/d/1fFcL91jSoTxusoBdxM_sr6TkLt65f25YPgfV-AYps4g/edit#gid=0

        Parameters
        ----------
        schemaname : string
            String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
            institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
            containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivatice,
            specimenDisposal, consent

        Returns
        -------
        pandas core dataframe
            Empty dataframe with OpenSpecimen&#39;s keys to the corresponding schema.
        data binary csv file
            The raw csv file 
        &#34;&#34;&#34;

        schemes = [&#34;cp&#34;, &#34;specimen&#34;, &#34;cpr&#34;, &#34;user&#34;, &#34;userRoles&#34;, &#34;site&#34;, &#34;shipment&#34;,
            &#34;institute&#34;, &#34;dpRequirement&#34;, &#34;distributionProtocol&#34;, &#34;distributionOrder&#34;, &#34;storageContainer&#34;, &#34;storageContainerType&#34;,
            &#34;containerShipment&#34;, &#34;cpe&#34;, &#34;masterSpecimen&#34;, &#34;participant&#34;, &#34;sr&#34;, &#34;visit&#34;, &#34;specimenAliquot&#34;, &#34;specimenDerivative&#34;,
            &#34;specimenDisposal&#34;, &#34;consent&#34;]
       
        assert schemaname in schemes, &#34;Non permissible schema please check documentation for permissible values&#34;

        endpoint = &#39;/input-file-template?schema=&#39; + str(schemaname)
        url = self.base_url + endpoint

        r = self.OS_request_gen.get_request(url)
    
        data = io.StringIO(r.text)
        ret_val = pandas.read_csv(data, sep=&#34;,&#34;,encoding=&#39;UTF-8&#39;, engine=&#39;python&#39;)
       
        return ret_val, data

    def upload_csv(self, filename, file):

        &#34;&#34;&#34;Upload a CSV file to OpenSpecimen

        This function handles the uploading of a CSV file to OpenSpecimen. This creates a job with a file-ID.
        With the file-ID the job then can be started via the function run_upload.

        Note
        ----
        The values are separated by comma &#39;,&#39;. This is the OpenSpecimen standard format.

        Parameters
        ----------
        filename : string
            The name of the file as string with the ending, here .csv . 
        
        file : binary
            The file itself which should get uploaded.

        Returns
        -------
        list
            The Job-ID as list with length 1.
        &#34;&#34;&#34;

        endpoint = &#39;/input-file&#39;
        url = self.base_url + endpoint
        files = [(&#39;file&#39;, (filename, file, &#39;text/csv&#39;))]

        r = self.OS_request_gen.post_request(url=url, files=files)

        return json.loads(r.text)[&#34;fileId&#34;]


    def run_upload(self, schemaname, fileid, operation = &#39;CREATE&#39;, dateformat = None, timeformat = None):

        &#34;&#34;&#34;Run a job which is already created.

        Runs a Job, which is already created. The schema and file-ID have to be known. Moreover, one has to specify if 
        the job updates already existing objects or create new ones.

        Note
        ----
        The date and timeformat can be left empty, if it is compatible with OpenSpecimen.

        Parameters
        ----------
        schemaname : string
            String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
            institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
            containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivative,
            specimenDisposal, consent

        fileid : string
            The file-ID, from OpenSpecimen generated, which is generated when the file is uploaded.

        operation : string
            The permissable operations are &#39;CREATE&#39; and &#39;UPDATE&#39;.

        dateformat : string
            An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen.

        timeformat : string
            An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen. 


        Returns
        -------
        string
            A tuple with the format (&#39;JOBID&#39;, &#39;Response Text&#39;).
        &#34;&#34;&#34;

        url = self.base_url
        payload = self.Json_fact.create_bulk_import_job(schemaname=schemaname, operation=operation, fileid=fileid,
                                                            dateformat=dateformat, timeformat=timeformat)
        r = self.OS_request_gen.post_request(url, data=payload)
        return (json.loads(r.text)[&#34;id&#34;], r.text)


    def get_job_status(self, jobid):

        &#34;&#34;&#34;Get the Job status.

        Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
        can be seen via GUI in JOBS. The number after # in the title is the ID. The codes are:
        200 : Bulk Import request was successfully processed.
        401 : Authorisation failed, user doesn’t have the authority.
        500 : Internal server error, encountered server error while performing operations.

        Parameters
        ----------
        jobid : int
            ID of the job.

        Returns
        -------
        string
            A string with the status code as mentioned above.
        &#34;&#34;&#34;

        endpoint = &#39;/&#39;+ str(jobid)
        url = self.base_url + endpoint
        
        r = self.OS_request_gen.get_request(url)

        return r.text


    def job_report(self, jobid):

        &#34;&#34;&#34;Download a job report.

        Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
        can be seen via GUI in JOBS or in the corresponding schema with View Past Imports. The number 
        after # in the title is the ID. Generates a JSON-dict of the JOB containing the information
        which were uploaded and the additional fields OS_IMPORT_STATUS, OS_ERROR_MESSAGE.
        The status and error message can be extracted when converted to a list with location [-2,-1],
        or when converted to a dict with keys [&#39;OS_IMPORT_STATUS&#39;] and [&#39;OS_ERROR_MESSAGE&#39;].

        Parameters
        ----------
        jobid : int
            ID of the job.

        Returns
        -------
        string
            Job details as CSV like string separated by &#39;,&#39;
        &#34;&#34;&#34;

        endpoint = &#39;/&#39; + str(jobid) + &#39;/output&#39;
        url = self.base_url + endpoint

        r = self.OS_request_gen.get_request(url)

        return r.text</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk"><code class="flex name class">
<span>class <span class="ident">csv_bulk</span></span>
</code></dt>
<dd>
<div class="desc"><p>Handles the OpenSpecimen CSV Bulk Importer via API.</p>
<p>Handles the API calls of the OpenSpecimen's Bulk Importer for all the different schemas.
This class can get the templates to a schema, upload the csv-files, run the job, get the job status
and get the job report.</p>
<h2 id="note">Note</h2>
<p>The OpenSpecimen Documentation of the Bulk Import can be seen at
<a href="https://openspecimen.atlassian.net/wiki/spaces/CAT/pages/440434702/Bulk+Import+via+API">https://openspecimen.atlassian.net/wiki/spaces/CAT/pages/440434702/Bulk+Import+via+API</a> .
File uploading in OpenSpecimen are two calls, which here are two seperated calls, via the
function bulk_import from the os_util class bulk_operations these calls get one call.</p>
<p>Constructor of the class csv_bulk</p>
<p>Constructor of the class csv_bulk. It also connects this class to the OpenSpecimen specific requests class
OS_request_gen, and the OpenSpecimen standard JSON-dict generator class JSON_factory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class csv_bulk:
    &#34;&#34;&#34;Handles the OpenSpecimen CSV Bulk Importer via API.

    Handles the API calls of the OpenSpecimen&#39;s Bulk Importer for all the different schemas. 
    This class can get the templates to a schema, upload the csv-files, run the job, get the job status
    and get the job report.

    Note
    ----
    The OpenSpecimen Documentation of the Bulk Import can be seen at 
    https://openspecimen.atlassian.net/wiki/spaces/CAT/pages/440434702/Bulk+Import+via+API .
    File uploading in OpenSpecimen are two calls, which here are two seperated calls, via the
    function bulk_import from the os_util class bulk_operations these calls get one call.
    &#34;&#34;&#34;

    def __init__(self):

        &#34;&#34;&#34;Constructor of the class csv_bulk

        Constructor of the class csv_bulk. It also connects this class to the OpenSpecimen specific requests class
        OS_request_gen, and the OpenSpecimen standard JSON-dict generator class JSON_factory
        &#34;&#34;&#34;
        self.base_url = config_manager.get_url() + &#39;/import-jobs&#39;
        self.auth = config_manager.get_auth()
        self.OS_request_gen = OS_request_gen(self.auth)
        self.Json_fact = Json_factory()

    def ausgabe(self):

        &#34;&#34;&#34;Testing of the URL and authentification.

        If there are any unexpected errors, one can easily test if the URL and login data is spelled correctly.
        The function prints the URL and login data to the output terminal, which was handed over to the class.
        &#34;&#34;&#34;

        print(self.base_url, self.OS_request_gen.auth)


    def get_template(self, schemaname):
    
        &#34;&#34;&#34;Get the Templates to the corresponding schema

        Get the Templates of a OpenSpecimen schema and load it into an empty pandas dataframe,
        where the OpenSpecimen specific keys are the header of the dataframe. To use this class, one has to know the 
        schemanames which are used in OpenSpecimen. They are written in camelCase.

        Note
        ----
        The schemanames can be seen at: https://docs.google.com/spreadsheets/d/1fFcL91jSoTxusoBdxM_sr6TkLt65f25YPgfV-AYps4g/edit#gid=0

        Parameters
        ----------
        schemaname : string
            String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
            institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
            containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivatice,
            specimenDisposal, consent

        Returns
        -------
        pandas core dataframe
            Empty dataframe with OpenSpecimen&#39;s keys to the corresponding schema.
        data binary csv file
            The raw csv file 
        &#34;&#34;&#34;

        schemes = [&#34;cp&#34;, &#34;specimen&#34;, &#34;cpr&#34;, &#34;user&#34;, &#34;userRoles&#34;, &#34;site&#34;, &#34;shipment&#34;,
            &#34;institute&#34;, &#34;dpRequirement&#34;, &#34;distributionProtocol&#34;, &#34;distributionOrder&#34;, &#34;storageContainer&#34;, &#34;storageContainerType&#34;,
            &#34;containerShipment&#34;, &#34;cpe&#34;, &#34;masterSpecimen&#34;, &#34;participant&#34;, &#34;sr&#34;, &#34;visit&#34;, &#34;specimenAliquot&#34;, &#34;specimenDerivative&#34;,
            &#34;specimenDisposal&#34;, &#34;consent&#34;]
       
        assert schemaname in schemes, &#34;Non permissible schema please check documentation for permissible values&#34;

        endpoint = &#39;/input-file-template?schema=&#39; + str(schemaname)
        url = self.base_url + endpoint

        r = self.OS_request_gen.get_request(url)
    
        data = io.StringIO(r.text)
        ret_val = pandas.read_csv(data, sep=&#34;,&#34;,encoding=&#39;UTF-8&#39;, engine=&#39;python&#39;)
       
        return ret_val, data

    def upload_csv(self, filename, file):

        &#34;&#34;&#34;Upload a CSV file to OpenSpecimen

        This function handles the uploading of a CSV file to OpenSpecimen. This creates a job with a file-ID.
        With the file-ID the job then can be started via the function run_upload.

        Note
        ----
        The values are separated by comma &#39;,&#39;. This is the OpenSpecimen standard format.

        Parameters
        ----------
        filename : string
            The name of the file as string with the ending, here .csv . 
        
        file : binary
            The file itself which should get uploaded.

        Returns
        -------
        list
            The Job-ID as list with length 1.
        &#34;&#34;&#34;

        endpoint = &#39;/input-file&#39;
        url = self.base_url + endpoint
        files = [(&#39;file&#39;, (filename, file, &#39;text/csv&#39;))]

        r = self.OS_request_gen.post_request(url=url, files=files)

        return json.loads(r.text)[&#34;fileId&#34;]


    def run_upload(self, schemaname, fileid, operation = &#39;CREATE&#39;, dateformat = None, timeformat = None):

        &#34;&#34;&#34;Run a job which is already created.

        Runs a Job, which is already created. The schema and file-ID have to be known. Moreover, one has to specify if 
        the job updates already existing objects or create new ones.

        Note
        ----
        The date and timeformat can be left empty, if it is compatible with OpenSpecimen.

        Parameters
        ----------
        schemaname : string
            String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
            institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
            containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivative,
            specimenDisposal, consent

        fileid : string
            The file-ID, from OpenSpecimen generated, which is generated when the file is uploaded.

        operation : string
            The permissable operations are &#39;CREATE&#39; and &#39;UPDATE&#39;.

        dateformat : string
            An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen.

        timeformat : string
            An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen. 


        Returns
        -------
        string
            A tuple with the format (&#39;JOBID&#39;, &#39;Response Text&#39;).
        &#34;&#34;&#34;

        url = self.base_url
        payload = self.Json_fact.create_bulk_import_job(schemaname=schemaname, operation=operation, fileid=fileid,
                                                            dateformat=dateformat, timeformat=timeformat)
        r = self.OS_request_gen.post_request(url, data=payload)
        return (json.loads(r.text)[&#34;id&#34;], r.text)


    def get_job_status(self, jobid):

        &#34;&#34;&#34;Get the Job status.

        Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
        can be seen via GUI in JOBS. The number after # in the title is the ID. The codes are:
        200 : Bulk Import request was successfully processed.
        401 : Authorisation failed, user doesn’t have the authority.
        500 : Internal server error, encountered server error while performing operations.

        Parameters
        ----------
        jobid : int
            ID of the job.

        Returns
        -------
        string
            A string with the status code as mentioned above.
        &#34;&#34;&#34;

        endpoint = &#39;/&#39;+ str(jobid)
        url = self.base_url + endpoint
        
        r = self.OS_request_gen.get_request(url)

        return r.text


    def job_report(self, jobid):

        &#34;&#34;&#34;Download a job report.

        Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
        can be seen via GUI in JOBS or in the corresponding schema with View Past Imports. The number 
        after # in the title is the ID. Generates a JSON-dict of the JOB containing the information
        which were uploaded and the additional fields OS_IMPORT_STATUS, OS_ERROR_MESSAGE.
        The status and error message can be extracted when converted to a list with location [-2,-1],
        or when converted to a dict with keys [&#39;OS_IMPORT_STATUS&#39;] and [&#39;OS_ERROR_MESSAGE&#39;].

        Parameters
        ----------
        jobid : int
            ID of the job.

        Returns
        -------
        string
            Job details as CSV like string separated by &#39;,&#39;
        &#34;&#34;&#34;

        endpoint = &#39;/&#39; + str(jobid) + &#39;/output&#39;
        url = self.base_url + endpoint

        r = self.OS_request_gen.get_request(url)

        return r.text</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.ausgabe"><code class="name flex">
<span>def <span class="ident">ausgabe</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Testing of the URL and authentification.</p>
<p>If there are any unexpected errors, one can easily test if the URL and login data is spelled correctly.
The function prints the URL and login data to the output terminal, which was handed over to the class.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ausgabe(self):

    &#34;&#34;&#34;Testing of the URL and authentification.

    If there are any unexpected errors, one can easily test if the URL and login data is spelled correctly.
    The function prints the URL and login data to the output terminal, which was handed over to the class.
    &#34;&#34;&#34;

    print(self.base_url, self.OS_request_gen.auth)</code></pre>
</details>
</dd>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_job_status"><code class="name flex">
<span>def <span class="ident">get_job_status</span></span>(<span>self, jobid)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the Job status.</p>
<p>Get the status of a job with the ID ::jobid:: . The status of the job has to be known and
can be seen via GUI in JOBS. The number after # in the title is the ID. The codes are:
200 : Bulk Import request was successfully processed.
401 : Authorisation failed, user doesn’t have the authority.
500 : Internal server error, encountered server error while performing operations.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>jobid</code></strong> :&ensp;<code>int</code></dt>
<dd>ID of the job.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>A string with the status code as mentioned above.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_job_status(self, jobid):

    &#34;&#34;&#34;Get the Job status.

    Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
    can be seen via GUI in JOBS. The number after # in the title is the ID. The codes are:
    200 : Bulk Import request was successfully processed.
    401 : Authorisation failed, user doesn’t have the authority.
    500 : Internal server error, encountered server error while performing operations.

    Parameters
    ----------
    jobid : int
        ID of the job.

    Returns
    -------
    string
        A string with the status code as mentioned above.
    &#34;&#34;&#34;

    endpoint = &#39;/&#39;+ str(jobid)
    url = self.base_url + endpoint
    
    r = self.OS_request_gen.get_request(url)

    return r.text</code></pre>
</details>
</dd>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_template"><code class="name flex">
<span>def <span class="ident">get_template</span></span>(<span>self, schemaname)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the Templates to the corresponding schema</p>
<p>Get the Templates of a OpenSpecimen schema and load it into an empty pandas dataframe,
where the OpenSpecimen specific keys are the header of the dataframe. To use this class, one has to know the
schemanames which are used in OpenSpecimen. They are written in camelCase.</p>
<h2 id="note">Note</h2>
<p>The schemanames can be seen at: <a href="https://docs.google.com/spreadsheets/d/1fFcL91jSoTxusoBdxM_sr6TkLt65f25YPgfV-AYps4g/edit#gid=0">https://docs.google.com/spreadsheets/d/1fFcL91jSoTxusoBdxM_sr6TkLt65f25YPgfV-AYps4g/edit#gid=0</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>schemaname</code></strong> :&ensp;<code>string</code></dt>
<dd>String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivatice,
specimenDisposal, consent</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas core dataframe</code></dt>
<dd>Empty dataframe with OpenSpecimen's keys to the corresponding schema.</dd>
<dt><code>data binary csv file</code></dt>
<dd>The raw csv file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_template(self, schemaname):

    &#34;&#34;&#34;Get the Templates to the corresponding schema

    Get the Templates of a OpenSpecimen schema and load it into an empty pandas dataframe,
    where the OpenSpecimen specific keys are the header of the dataframe. To use this class, one has to know the 
    schemanames which are used in OpenSpecimen. They are written in camelCase.

    Note
    ----
    The schemanames can be seen at: https://docs.google.com/spreadsheets/d/1fFcL91jSoTxusoBdxM_sr6TkLt65f25YPgfV-AYps4g/edit#gid=0

    Parameters
    ----------
    schemaname : string
        String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
        institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
        containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivatice,
        specimenDisposal, consent

    Returns
    -------
    pandas core dataframe
        Empty dataframe with OpenSpecimen&#39;s keys to the corresponding schema.
    data binary csv file
        The raw csv file 
    &#34;&#34;&#34;

    schemes = [&#34;cp&#34;, &#34;specimen&#34;, &#34;cpr&#34;, &#34;user&#34;, &#34;userRoles&#34;, &#34;site&#34;, &#34;shipment&#34;,
        &#34;institute&#34;, &#34;dpRequirement&#34;, &#34;distributionProtocol&#34;, &#34;distributionOrder&#34;, &#34;storageContainer&#34;, &#34;storageContainerType&#34;,
        &#34;containerShipment&#34;, &#34;cpe&#34;, &#34;masterSpecimen&#34;, &#34;participant&#34;, &#34;sr&#34;, &#34;visit&#34;, &#34;specimenAliquot&#34;, &#34;specimenDerivative&#34;,
        &#34;specimenDisposal&#34;, &#34;consent&#34;]
   
    assert schemaname in schemes, &#34;Non permissible schema please check documentation for permissible values&#34;

    endpoint = &#39;/input-file-template?schema=&#39; + str(schemaname)
    url = self.base_url + endpoint

    r = self.OS_request_gen.get_request(url)

    data = io.StringIO(r.text)
    ret_val = pandas.read_csv(data, sep=&#34;,&#34;,encoding=&#39;UTF-8&#39;, engine=&#39;python&#39;)
   
    return ret_val, data</code></pre>
</details>
</dd>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.job_report"><code class="name flex">
<span>def <span class="ident">job_report</span></span>(<span>self, jobid)</span>
</code></dt>
<dd>
<div class="desc"><p>Download a job report.</p>
<p>Get the status of a job with the ID ::jobid:: . The status of the job has to be known and
can be seen via GUI in JOBS or in the corresponding schema with View Past Imports. The number
after # in the title is the ID. Generates a JSON-dict of the JOB containing the information
which were uploaded and the additional fields OS_IMPORT_STATUS, OS_ERROR_MESSAGE.
The status and error message can be extracted when converted to a list with location [-2,-1],
or when converted to a dict with keys ['OS_IMPORT_STATUS'] and ['OS_ERROR_MESSAGE'].</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>jobid</code></strong> :&ensp;<code>int</code></dt>
<dd>ID of the job.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>Job details as CSV like string separated by ','</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def job_report(self, jobid):

    &#34;&#34;&#34;Download a job report.

    Get the status of a job with the ID ::jobid:: . The status of the job has to be known and 
    can be seen via GUI in JOBS or in the corresponding schema with View Past Imports. The number 
    after # in the title is the ID. Generates a JSON-dict of the JOB containing the information
    which were uploaded and the additional fields OS_IMPORT_STATUS, OS_ERROR_MESSAGE.
    The status and error message can be extracted when converted to a list with location [-2,-1],
    or when converted to a dict with keys [&#39;OS_IMPORT_STATUS&#39;] and [&#39;OS_ERROR_MESSAGE&#39;].

    Parameters
    ----------
    jobid : int
        ID of the job.

    Returns
    -------
    string
        Job details as CSV like string separated by &#39;,&#39;
    &#34;&#34;&#34;

    endpoint = &#39;/&#39; + str(jobid) + &#39;/output&#39;
    url = self.base_url + endpoint

    r = self.OS_request_gen.get_request(url)

    return r.text</code></pre>
</details>
</dd>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.run_upload"><code class="name flex">
<span>def <span class="ident">run_upload</span></span>(<span>self, schemaname, fileid, operation='CREATE', dateformat=None, timeformat=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a job which is already created.</p>
<p>Runs a Job, which is already created. The schema and file-ID have to be known. Moreover, one has to specify if
the job updates already existing objects or create new ones.</p>
<h2 id="note">Note</h2>
<p>The date and timeformat can be left empty, if it is compatible with OpenSpecimen.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>schemaname</code></strong> :&ensp;<code>string</code></dt>
<dd>String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivative,
specimenDisposal, consent</dd>
<dt><strong><code>fileid</code></strong> :&ensp;<code>string</code></dt>
<dd>The file-ID, from OpenSpecimen generated, which is generated when the file is uploaded.</dd>
<dt><strong><code>operation</code></strong> :&ensp;<code>string</code></dt>
<dd>The permissable operations are 'CREATE' and 'UPDATE'.</dd>
<dt><strong><code>dateformat</code></strong> :&ensp;<code>string</code></dt>
<dd>An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen.</dd>
<dt><strong><code>timeformat</code></strong> :&ensp;<code>string</code></dt>
<dd>An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>A tuple with the format ('JOBID', 'Response Text').</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_upload(self, schemaname, fileid, operation = &#39;CREATE&#39;, dateformat = None, timeformat = None):

    &#34;&#34;&#34;Run a job which is already created.

    Runs a Job, which is already created. The schema and file-ID have to be known. Moreover, one has to specify if 
    the job updates already existing objects or create new ones.

    Note
    ----
    The date and timeformat can be left empty, if it is compatible with OpenSpecimen.

    Parameters
    ----------
    schemaname : string
        String in camelCase of the schema, permissable values are: cp, specimen, cpr, user, userRoles, site, shipment,
        institute, dpRequirement, distributionProtocol, distributionOrder, storageContainer, storageContainertype,
        containerShipment, cpe, masterSpecimen, participant, sr, visit, specimenAliquot, specimenDerivative,
        specimenDisposal, consent

    fileid : string
        The file-ID, from OpenSpecimen generated, which is generated when the file is uploaded.

    operation : string
        The permissable operations are &#39;CREATE&#39; and &#39;UPDATE&#39;.

    dateformat : string
        An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen.

    timeformat : string
        An optional parameter, which has to be specified if the format is not compatible with OpenSpecimen. 


    Returns
    -------
    string
        A tuple with the format (&#39;JOBID&#39;, &#39;Response Text&#39;).
    &#34;&#34;&#34;

    url = self.base_url
    payload = self.Json_fact.create_bulk_import_job(schemaname=schemaname, operation=operation, fileid=fileid,
                                                        dateformat=dateformat, timeformat=timeformat)
    r = self.OS_request_gen.post_request(url, data=payload)
    return (json.loads(r.text)[&#34;id&#34;], r.text)</code></pre>
</details>
</dd>
<dt id="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.upload_csv"><code class="name flex">
<span>def <span class="ident">upload_csv</span></span>(<span>self, filename, file)</span>
</code></dt>
<dd>
<div class="desc"><p>Upload a CSV file to OpenSpecimen</p>
<p>This function handles the uploading of a CSV file to OpenSpecimen. This creates a job with a file-ID.
With the file-ID the job then can be started via the function run_upload.</p>
<h2 id="note">Note</h2>
<p>The values are separated by comma ','. This is the OpenSpecimen standard format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>string</code></dt>
<dd>The name of the file as string with the ending, here .csv .</dd>
<dt><strong><code>file</code></strong> :&ensp;<code>binary</code></dt>
<dd>The file itself which should get uploaded.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>The Job-ID as list with length 1.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def upload_csv(self, filename, file):

    &#34;&#34;&#34;Upload a CSV file to OpenSpecimen

    This function handles the uploading of a CSV file to OpenSpecimen. This creates a job with a file-ID.
    With the file-ID the job then can be started via the function run_upload.

    Note
    ----
    The values are separated by comma &#39;,&#39;. This is the OpenSpecimen standard format.

    Parameters
    ----------
    filename : string
        The name of the file as string with the ending, here .csv . 
    
    file : binary
        The file itself which should get uploaded.

    Returns
    -------
    list
        The Job-ID as list with length 1.
    &#34;&#34;&#34;

    endpoint = &#39;/input-file&#39;
    url = self.base_url + endpoint
    files = [(&#39;file&#39;, (filename, file, &#39;text/csv&#39;))]

    r = self.OS_request_gen.post_request(url=url, files=files)

    return json.loads(r.text)[&#34;fileId&#34;]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="OpenSpecimenAPIconnector.os_core" href="index.html">OpenSpecimenAPIconnector.os_core</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk">csv_bulk</a></code></h4>
<ul class="two-column">
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.ausgabe" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.ausgabe">ausgabe</a></code></li>
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_job_status" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_job_status">get_job_status</a></code></li>
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_template" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.get_template">get_template</a></code></li>
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.job_report" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.job_report">job_report</a></code></li>
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.run_upload" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.run_upload">run_upload</a></code></li>
<li><code><a title="OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.upload_csv" href="#OpenSpecimenAPIconnector.os_core.csv_bulk.csv_bulk.upload_csv">upload_csv</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>